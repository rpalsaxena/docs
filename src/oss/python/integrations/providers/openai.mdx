---
title: OpenAI
---

This page covers all LangChain integrations with [OpenAI](https://en.wikipedia.org/wiki/OpenAI)

{/* ## Installation and setup

<CodeGroup>
    ```bash pip
    pip install langchain-openai
    ```

    ```bash uv
    uv add langchain-openai
    ```
</CodeGroup>

Get an [OpenAI Platform](https://platform.openai.com/docs/overview) API key and set it as the environment variable `OPENAI_API_KEY`. */}

## Model interfaces

<Columns cols={2}>
    <Card title="ChatOpenAI" href="/oss/integrations/chat/openai" cta="Get started" icon="message" arrow>
        OpenAI chat models.
    </Card>
    <Card title="AzureChatOpenAI" href="/oss/integrations/chat/azure_chat_openai" cta="Get started" icon="microsoft" arrow>
        Wrapper for OpenAI chat models hosted on Azure.
    </Card>
    <Card title="OpenAI" href="/oss/integrations/llms/openai" cta="Get started" icon="i-cursor" arrow>
        (Legacy) OpenAI text completion models.
    </Card>
    <Card title="AzureOpenAI" href="/oss/integrations/llms/azure_openai" cta="Get started" icon="microsoft" arrow>
        Wrapper for (legacy) OpenAI text completion models hosted on Azure.
    </Card>
    <Card title="OpenAIEmbeddings" href="/oss/integrations/text_embedding/openai" cta="Get started" icon="layer-group" arrow>
        OpenAI embedding models.
    </Card>
    <Card title="AzureOpenAIEmbeddings" href="/oss/integrations/text_embedding/azure_openai" cta="Get started" icon="microsoft" arrow>
        Wrapper for OpenAI embedding models hosted on Azure.
    </Card>
</Columns>

## Tools and toolkits
<Columns cols={2}>
    <Card title="Dall-E Image Generator" href="/oss/integrations/tools/dalle_image_generator" cta="Get started" icon="image" arrow>
        Text-to-image generation using OpenAI's Dall-E models.
    </Card>
</Columns>

## Retrievers

<Columns cols={2}>
    <Card title="ChatGPTPluginRetriever" href="/oss/integrations/retrievers/chatgpt-plugin" cta="Get started" icon="download" arrow>
        Retrieve real-time information; e.g., sports scores, stock prices, the latest news, etc.
    </Card>
</Columns>

## Document loaders

<Columns cols={2}>
    <Card title="ChatGPTLoader" href="/oss/integrations/document_loaders/chatgpt_loader" cta="Get started" icon="file" arrow>
        Load `conversations.json` from your ChatGPT data export folder.
    </Card>
</Columns>

## Middleware

Middleware specifically designed for OpenAI models. Learn more about [middleware](/oss/langchain/middleware/overview).

:::python

| Middleware | Description |
|------------|-------------|
| [Content moderation](#content-moderation) | Moderate agent traffic using OpenAI's moderation endpoint |

:::

### Content moderation

Moderate agent traffic (user input, model output, and tool results) using OpenAI's moderation endpoint to detect and handle unsafe content. Content moderation is useful for the following:

- Applications requiring content safety and compliance
- Filtering harmful, hateful, or inappropriate content
- Customer-facing agents that need safety guardrails
- Meeting platform moderation requirements

<Info>
    Learn more about [OpenAI's moderation models](https://platform.openai.com/docs/guides/moderation) and categories.
</Info>

:::python
**API reference:** @[`OpenAIModerationMiddleware`]

```python
from langchain_openai import ChatOpenAI
from langchain_openai.middleware import OpenAIModerationMiddleware
from langchain.agents import create_agent

agent = create_agent(
    model=ChatOpenAI(model="gpt-4o"),
    tools=[search_tool, database_tool],
    middleware=[
        OpenAIModerationMiddleware(
            model="omni-moderation-latest",
            check_input=True,
            check_output=True,
            exit_behavior="end",
        ),
    ],
)
```
:::

<Accordion title="Configuration options">

:::python
<ParamField body="model" type="ModerationModel" default="omni-moderation-latest">
    OpenAI moderation model to use. Options: `'omni-moderation-latest'`, `'omni-moderation-2024-09-26'`, `'text-moderation-latest'`, `'text-moderation-stable'`
</ParamField>

<ParamField body="check_input" type="bool" default="True">
    Whether to check user input messages before the model is called
</ParamField>

<ParamField body="check_output" type="bool" default="True">
    Whether to check model output messages after the model is called
</ParamField>

<ParamField body="check_tool_results" type="bool" default="False">
    Whether to check tool result messages before the model is called
</ParamField>

<ParamField body="exit_behavior" type="string" default="end">
    How to handle violations when content is flagged. Options:

    - `'end'` - End agent execution immediately with a violation message
    - `'error'` - Raise `OpenAIModerationError` exception
    - `'replace'` - Replace the flagged content with the violation message and continue
</ParamField>

<ParamField body="violation_message" type="str | None">
    Custom template for violation messages. Supports template variables:

    - `{categories}` - Comma-separated list of flagged categories
    - `{category_scores}` - JSON string of category scores
    - `{original_content}` - The original flagged content

    Default: `"I'm sorry, but I can't comply with that request. It was flagged for {categories}."`
</ParamField>

<ParamField body="client" type="OpenAI | None">
    Optional pre-configured OpenAI client to reuse. If not provided, a new client will be created.
</ParamField>

<ParamField body="async_client" type="AsyncOpenAI | None">
    Optional pre-configured AsyncOpenAI client to reuse. If not provided, a new async client will be created.
</ParamField>
:::

</Accordion>

<Accordion title="Full example">

The middleware integrates OpenAI's moderation endpoint to check content at different stages:

**Moderation stages:**
- `check_input` - User messages before model call
- `check_output` - AI messages after model call
- `check_tool_results` - Tool outputs before model call

**Exit behaviors:**
- `'end'` (default) - Stop execution with violation message
- `'error'` - Raise exception for application handling
- `'replace'` - Replace flagged content and continue

:::python
```python
from langchain_openai import ChatOpenAI
from langchain_openai.middleware import OpenAIModerationMiddleware
from langchain.agents import create_agent


# Basic moderation
agent = create_agent(
    model=ChatOpenAI(model="gpt-4o"),
    tools=[search_tool, customer_data_tool],
    middleware=[
        OpenAIModerationMiddleware(
            model="omni-moderation-latest",
            check_input=True,
            check_output=True,
        ),
    ],
)

# Strict moderation with custom message
agent_strict = create_agent(
    model=ChatOpenAI(model="gpt-4o"),
    tools=[search_tool, customer_data_tool],
    middleware=[
        OpenAIModerationMiddleware(
            model="omni-moderation-latest",
            check_input=True,
            check_output=True,
            check_tool_results=True,
            exit_behavior="error",
            violation_message=(
                "Content policy violation detected: {categories}. "
                "Please rephrase your request."
            ),
        ),
    ],
)

# Moderation with replacement behavior
agent_replace = create_agent(
    model=ChatOpenAI(model="gpt-4o"),
    tools=[search_tool],
    middleware=[
        OpenAIModerationMiddleware(
            check_input=True,
            exit_behavior="replace",
            violation_message="[Content removed due to safety policies]",
        ),
    ],
)
```
:::

</Accordion>

## Other

<Columns cols={2}>
    <Card title="Adapter" href="/oss/integrations/adapters/openai" cta="Get started" icon="arrows-left-right" arrow>
        Adapt LangChain models to OpenAI APIs.
    </Card>
    <Card title="OpenAIModerationChain" href="https://python.langchain.com/v0.1/docs/guides/productionization/safety/moderation" cta="Get started" icon="link" arrow>
        Detect text that could be hateful, violent, etc.
    </Card>
</Columns>
